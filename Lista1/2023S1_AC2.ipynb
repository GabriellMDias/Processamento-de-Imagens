{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOIU9SaeIAz-"
   },
   "source": [
    "# <center>Centro Universitário Facens<br/></center>\n",
    "<br/>\n",
    "<font size=\"4\"><center><b>Disciplina: Processamento de imagens</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Renato M. Silva</center></font>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## <center>Avaliação Continuada 2 (AC2)</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### <center>Nome e RA dos componentes do grupo</center>\n",
    "\n",
    "    \n",
    "| Nome     |      RA      | \n",
    "|:-        |:-------------:|\n",
    "|Gabriel Moreira Dias|200903| \n",
    "|          |              | \n",
    "|          |              | \n",
    "|          |              | \n",
    "|          |              | \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Instruções\n",
    "**1**. Siga boas práticas de programação:\n",
    "- dar nomes intuitivos para as variáveis\n",
    "- dar nomes intuitivos para as funções\n",
    "\n",
    "**2**. O trabalho pode ser feito em grupos de até 5 pessoas. Porém, todos os componentes devem ser da mesma turma de Processamento de Imagens. \n",
    " - Caso algum grupo contenha alguém de uma turma diferente, todo o grupo receberá nota zero.\n",
    " - Apenas uma pessoa do grupo deve submeter o trabalho. \n",
    " - Você deve submeter apenas o arquivo .ipynb.\n",
    "\n",
    "**3**. Em todos os exercícios, as imagens finais solicitadas devem estar no formato **uint8**.\n",
    "\n",
    "**4**. Cuidado com plágio. Se for detectado plágio entre grupos, a punição será dada para todos os componentes dos grupos envolvidos. \n",
    "\n",
    "**5**. Antes de submeter o notebook, certifique-se que não há erros de código. Uma forma de se certificar disso é usar a opção **\"Reiniciar Kernel e executar todas as células\"** do Jupyter ou a opção **\"Reiniciar e executar tudo\"** do Google Colab. \n",
    "\n",
    "**6**. A única biblioteca de processamento de imagens permitida neste trabalho é a **OpenCV**. Porém, alguns exercícios poderão limitar algumas funções dessa biblioteca que poderão ser usadas. \n",
    "\n",
    "**7**. Em todos os exercícios que pedirem para salvar a imagem resultante, tome cuidado de converter a imagem para BGR antes de salvá-la pois esse é o formato padrão da biblioteca OpenCV. Caso contrário, os canais de cores da imagem resultante ficarão trocados. \n",
    "\n",
    "**8**. Em todos os exercícios, caso o resultado seja uma ou mais imagens, você deve mostrá-las na tela. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercício 1\n",
    "\n",
    "Implemente uma função que consiga fazer a detecção de movimentos em um vídeo. Ela deverá extrair os frames do vídeo e, para cada frame, deve calcular o **histograma** da imagem e compará-lo com os últimos histogramas calculados. Quando a diferença entre estes ultrapassar um limiar pré-estabelecido, simule um alarme interrompendo a função e retornando uma mensagem de alerta. Utilize uma função de comparação que julgar conveniente. \n",
    "- A diferença entre dois histogramas pode ser calculada por meio de medidas estatísticas, como média, desvio padrão, mediana, IQR, etc. \n",
    "\n",
    "Teste a função no vídeo *videos/cameraEscondida.mp4*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movimento detectado!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def desvioPadrao(hist):\n",
    "    somatorio = 0\n",
    "    for i in range(len(hist)):\n",
    "        somatorio += (hist[i] - hist.mean()) * (hist[i] - hist.mean())\n",
    "    return (somatorio/len(hist)) ** 0.5\n",
    "    \n",
    "\n",
    "def detectaMov(videoSrc, limiar=1):\n",
    "    cap = cv2.VideoCapture(videoSrc)\n",
    "    if not cap.isOpened():\n",
    "        print('Erro ao abrir o arquivo de vídeo.')\n",
    "\n",
    "    last_hist = None\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    desvioPadrao(hist)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "\n",
    "        if last_hist is not None:\n",
    "            hist_diff = abs(desvioPadrao(hist) - desvioPadrao(last_hist))\n",
    "            if hist_diff > limiar:\n",
    "                print(\"Movimento detectado!\")\n",
    "                break\n",
    "        \n",
    "        last_hist = hist\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "detectaMov('./videos/cameraEscondida.mp4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercício 2\n",
    "\n",
    "\n",
    "Implemente um algoritmo que faça a combinação das imagens **figs/facensLogo.png** e **facensVistaAerea.webp** para gerar o resultado apresentado abaixo. Salve a imagem resultante na pasta **figsResultado** com o nome **ex02.png**\n",
    "\n",
    "Para atingir esse resultado, as únicas funções da biblioteca **OpencCV** que poderão ser aplicadas são: **warpAffine**, **getRotationMatrix2D**, **resize**, **cvtColor** e aquelas que sirvam para abrir ou salvar uma imagem. Todas as demais operações deverão ser implementadas por meio de operações matriciais, podendo ser aplicadas função da biblioteca **NumPy**. \n",
    "\n",
    "**Dicas**: \n",
    "- Divida a imagem **facensVistaAerea.webp** em quatro partes iguais. Depois disso, aplique rotação em cada uma das 4 partes.\n",
    "- Para remover o fundo da imagem **figs/facensLogo.png**, você pode usar a segmentação por limiarização. Depois disso, você pode rotacionar cada uma dos quatro quadrantes para conseguir atingir o efeito mostrado na imagem abaixo.\n",
    "- Você pode usar as operações de soma e de escalamento para ajudar a atingir a imagem alvo.\n",
    "\n",
    "<center>\n",
    "<div style=\"display:inline-block;\">\n",
    "    <div style=\"padding: 5px; float: left;\">\n",
    "        <img src=\"figsNotebook/facens1.jpg\" width=\"400\" height=\"400\" />\n",
    "    </div>\n",
    "</div> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rotacao(img, theta):\n",
    "  matAfim = np.array([\n",
    "      [np.cos(theta), np.sin(theta), (1 - np.cos(theta))*(img.shape[1]/2) - np.sin(theta)*(img.shape[0]/2)],\n",
    "      [-np.sin(theta), np.cos(theta), np.sin(theta)*(img.shape[1]/2)+(1-np.cos(theta))*(img.shape[0]/2)]\n",
    "  ], dtype = np.float64)\n",
    "\n",
    "  larg = img.shape[1]\n",
    "  alt = img.shape[0]\n",
    "\n",
    "  img = cv2.warpAffine(src = img, M = matAfim, dsize = (larg, alt), flags = cv2.INTER_CUBIC)\n",
    "\n",
    "  return img\n",
    "\n",
    "facensLogo = cv2.cvtColor(cv2.imread('figs/facensLogo.png'), cv2.COLOR_BGR2GRAY)\n",
    "facensAerea = cv2.imread('figs/facensVistaAerea.webp')\n",
    "altura, largura, _ = facensAerea.shape\n",
    "m1 = rotacao(facensAerea[0:int(abs(altura/2)),0:int(abs(largura/2))], 0.45)\n",
    "m2 = rotacao(facensAerea[0:int(abs(altura/2)),int(abs(largura/2)):], -0.45)\n",
    "m3 = rotacao(facensAerea[int(abs(altura/2)):,0:int(abs(largura/2))], -0.45)\n",
    "m4 = rotacao(facensAerea[int(abs(altura/2)):,int(abs(largura/2)):], 0.45)\n",
    "\n",
    "img_final = np.zeros([altura,largura, 3], dtype=np.uint8)\n",
    "img_final[0:int(abs(altura/2)),0:int(abs(largura/2))] = m1\n",
    "img_final[0:int(abs(altura/2)),int(abs(largura/2)):] = m2\n",
    "img_final[int(abs(altura/2)):,0:int(abs(largura/2))] = m3\n",
    "img_final[int(abs(altura/2)):,int(abs(largura/2)):] = m4\n",
    "\n",
    "\n",
    "facensLogo = cv2.cvtColor(cv2.imread('figs/facensLogo.png'), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Calcula as coordenadas para centralizar a imagem recortada na imagem \n",
    "x = int((largura - facensLogo.shape[1]) / 2)\n",
    "y = int((altura - facensLogo.shape[0]) / 2)\n",
    "\n",
    "for i in range(facensLogo.shape[0]):\n",
    "    for j in range(facensLogo.shape[1]):\n",
    "        if facensLogo[i,j] < 180:\n",
    "          img_final[y+i, x+j] = [255,255,255]\n",
    "\n",
    "\n",
    "cv2.imwrite('figsResultado/ex02.png', img_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercicio 3\n",
    "\n",
    "Implemente uma função que receba uma imagem e retorne três imagens novas: uma contendo apenas os objetos com cor predominantemente vermelhas, outro com os objetos que possuem cor predominantemente verde e uma com os objetos com cor predominantemente azuis. Os demais objetos devem desaparecer da imagem resultante, transformando seus pixels para o valor 0. \n",
    "\n",
    "Para atingir o objetivo deste exercício é permitido usar apenas a biblioteca NumPy. As únicas funções da biblioteca OpenCV permitidas são a **cvtColor** e aquelas que abrem ou salvam uma imagem. \n",
    "\n",
    "Teste sua função passando como entrada a imagem **figs/objetos.png**. Salve as imagens resultantes na pasta \"**figsResultado**\" com os seguintes nomes: **ex03_objetosVermelhos.png**, **ex03_objetosVerdes.png** e **ex03_objetosAzuis.png**.\n",
    "\n",
    "Dicas: \n",
    "\n",
    " - Usando a biblioteca Numpy, é possível selecionar apenas os valores de uma determinada matriz que atendem a mais de uma restrição. Por exemplo, supondo que você queira transformar os valores de uma matriz que sejam maiores que 50 e menores que 100 para -1, você poderia aplicar a seguinte operação:\n",
    "\n",
    "```matriz[ (matriz>50) & (matriz<100) ] = -1 ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def separa_cores(img):\n",
    "    # Transforma a imagem de BGR para HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define as faixas de cores a serem isoladas em cada canal\n",
    "    faixas_cores = [\n",
    "        ([0, 70, 50], [10, 255, 255]),   # vermelho\n",
    "        ([40, 70, 50], [80, 255, 255]),  # verde\n",
    "        ([100, 70, 50], [140, 255, 255]) # azul\n",
    "    ]\n",
    "\n",
    "    # Cria máscaras para isolar cada cor\n",
    "    mascaras = []\n",
    "    for (cor_min, cor_max) in faixas_cores:\n",
    "        cor_min = np.array(cor_min, dtype=np.uint8)\n",
    "        cor_max = np.array(cor_max, dtype=np.uint8)\n",
    "        mascara = ((hsv >= cor_min) & (hsv <= cor_max)).all(axis=2)\n",
    "        mascaras.append(mascara)\n",
    "\n",
    "    # Cria imagens com cada cor isolada\n",
    "    vermelho = np.zeros_like(img)\n",
    "    vermelho[mascaras[0]] = img[mascaras[0]]\n",
    "    verde = np.zeros_like(img)\n",
    "    verde[mascaras[1]] = img[mascaras[1]]\n",
    "    azul = np.zeros_like(img)\n",
    "    azul[mascaras[2]] = img[mascaras[2]]\n",
    "\n",
    "    return vermelho, verde, azul\n",
    "\n",
    "# Carrega a imagem de entrada\n",
    "img = cv2.imread('figs/objetos.png')\n",
    "\n",
    "# Chama a função para separar as cores\n",
    "vermelho, verde, azul = separa_cores(img)\n",
    "\n",
    "# Salva as imagens resultantes\n",
    "cv2.imwrite('figsResultado/ex03_objetosVermelhos.png', vermelho)\n",
    "cv2.imwrite('figsResultado/ex03_objetosVerdes.png', verde)\n",
    "cv2.imwrite('figsResultado/ex03_objetosAzuis.png', azul)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Exercicio 4\n",
    "\n",
    "\n",
    "Faça uma função que desenhe um rosto. Essa função deve receber como parâmetro a cor do rosto, dos olhos, do nariz e da boca. \n",
    "\n",
    "A função deve funcionar para todas as cores primárias, secundárias e, também, preto e branco. No entanto, só é permitido criar os objetos que formam o rosto com as cores primárias. Para gerar objetos com preto, branco e cores secundárias, você deverá fazer operações aritméticas usando objetos gerados com as cores primárias. \n",
    "\n",
    "Por exemplo, supondo que essa função tenha recebido rosto=\"preto\", olhos=\"vermelho\", nariz=\"branco\", boca=\"verde\" como entrada, ela deveria produzir o rosto similar ao mostrado abaixo. \n",
    "\n",
    "-  Neste exercício é permitido usar apenas a biblioteca NumPy. As únicas funções da biblioteca OpenCV permitidas são a **cvtColor** e aquelas que abrem ou salvam uma imagem. \n",
    "\n",
    "- A imagem resultante não precisa ser igual a mostrada no exemplo. Pode exercer sua criatividade, desde que o rosto, olhos, boca e nariz sejam criados por meio de operações matriciais.\n",
    "\n",
    "- Teste sua função com três entradas diferentes e salve as imagens na pasta **figsResultado** com os nomes: ex04_rosto1.png, ex04_rosto2.png, ex04_rosto3.png\n",
    "\n",
    "\n",
    "<center>\n",
    "<div style=\"display:inline-block;\">\n",
    "    <div style=\"padding: 5px; float: left;\">\n",
    "        <img src=\"figsNotebook/rosto.png\" width=\"150\" height=\"150\" />\n",
    "    </div>\n",
    "</div> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def criaRosto(rosto, olhos, nariz, boca):\n",
    "    # Define as cores\n",
    "    vermelho = [0, 0, 255]\n",
    "    verde = [0, 255, 0]\n",
    "    azul = [255, 0, 0]\n",
    "    cores={\n",
    "        \"vermelho\": vermelho,\n",
    "        \"verde\": verde,\n",
    "        \"azul\": azul,\n",
    "        \"preto\": [vermelho[i] * verde[i] for i in range(3)],\n",
    "        \"branco\": [vermelho[i] + verde[i] + azul [i] for i in range(3)],\n",
    "        \"amarelo\": [vermelho[i] + verde[i] for i in range(3)],\n",
    "        \"roxo\": [vermelho[i] + azul[i] for i in range(3)],\n",
    "        \"ciano\": [verde[i] + azul[i] for i in range(3)]\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Cria rosto\n",
    "    rosto = np.ones([250,250,3], dtype=np.uint8) * cores[rosto]\n",
    "\n",
    "    # Desenha os olhos\n",
    "    rosto[50:100,50:100] = cores[olhos]\n",
    "    rosto[50:100,150:200] = cores[olhos]\n",
    "\n",
    "    #Desenha o Nariz\n",
    "    rosto[120:170, 115:135] = cores[nariz]\n",
    "\n",
    "    #Desenha a Boca\n",
    "    rosto[200:210,40:210] = cores[boca]\n",
    "\n",
    "    return rosto\n",
    "\n",
    "cv2.imwrite('figsResultado/ex04_rosto1.png', criaRosto(rosto=\"preto\", olhos=\"vermelho\", nariz=\"branco\", boca=\"verde\"))\n",
    "cv2.imwrite('figsResultado/ex04_rosto2.png', criaRosto(rosto=\"roxo\", olhos=\"amarelo\", nariz=\"ciano\", boca=\"branco\"))\n",
    "cv2.imwrite('figsResultado/ex04_rosto3.png', criaRosto(rosto=\"amarelo\", olhos=\"azul\", nariz=\"vermelho\", boca=\"preto\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercicio 5\n",
    "\n",
    "Utilize operações morfológicas nas imagens **figs/manequim.png** e **figs/tabuleiro.jpg** para remover todos os pontos brancos. Por outro lado, use as operaçòes morfológicas para remover apenas os círculos menores da imagem **figs/circulos.tif**, deixando apenas os círculos maiores. \n",
    "\n",
    "\n",
    "Salve as imagens resultantes na pasta **figsResultado** com os nomes ex05_manequim.png, ex05_tabuleiro.png e ex05_circulos.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "manequim = cv2.imread('figs/manequim.png', cv2.IMREAD_GRAYSCALE)\n",
    "tabuleiro = cv2.imread('figs/tabuleiro.png', cv2.IMREAD_GRAYSCALE)\n",
    "circulos = cv2.imread('figs/circulos.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (16, 16))\n",
    "kernel_circulos = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (12, 12))\n",
    "\n",
    "# Remover pontos brancos das imagens manequim e tabuleiro\n",
    "manequim_sem_pontos = cv2.erode(manequim, kernel, iterations=1)\n",
    "tabuleiro_sem_pontos = cv2.erode(tabuleiro, kernel, iterations=1)\n",
    "\n",
    "# Remover apenas os círculos menores da imagem circulos\n",
    "circulos_sem_circulos_pequenos = cv2.erode(circulos, kernel_circulos, iterations=1)\n",
    "\n",
    "cv2.imwrite('figsResultado/ex05_manequim.png', manequim_sem_pontos)\n",
    "cv2.imwrite('figsResultado/ex05_tabuleiro.png', tabuleiro_sem_pontos)\n",
    "cv2.imwrite('figsResultado/ex05_circulos.png', circulos_sem_circulos_pequenos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercicio 6\n",
    "\n",
    "Aplique um filtro para borrar as extremidades da imagem **figs/vista.jpg** para que ela fique com o efeito mostrado na imagem abaixo. Salve a imagem resultante na pasta **figsResultado** com o nome **ex06_vista.png**\n",
    "\n",
    "<img src=\"figsNotebook/vista_blur.jpg\" width=\"500\" height=\"128\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Carrega a imagem\n",
    "img = cv2.imread('figs/vista.jpg')\n",
    "\n",
    "# Aplica o filtro de borramento na imagem inteira\n",
    "img_borrada = cv2.GaussianBlur(img, (31, 31), 0)\n",
    "\n",
    "# Recorta as bordas da imagem\n",
    "altura, largura, _ = img.shape\n",
    "border_size = 200\n",
    "img_recortada = img[border_size:altura-border_size, border_size:largura-border_size]\n",
    "\n",
    "# Obtém as dimensões da imagem borrada\n",
    "altura_b, largura_b, _ = img_borrada.shape\n",
    "\n",
    "# Calcula as coordenadas para centralizar a imagem recortada na imagem borrada\n",
    "x = int((largura_b - img_recortada.shape[1]) / 2)\n",
    "y = int((altura_b - img_recortada.shape[0]) / 2)\n",
    "\n",
    "# Junta a imagem recortada no centro da imagem borrada\n",
    "for i in range(img_recortada.shape[0]):\n",
    "    for j in range(img_recortada.shape[1]):\n",
    "        img_borrada[y+i, x+j] = img_recortada[i, j]\n",
    "\n",
    "# Salva a imagem resultante\n",
    "cv2.imwrite('figsResultado/ex06_vista.png', img_borrada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercicio 7\n",
    "\n",
    "Sabe-se que as técnicas de filtragem podem ser usadas para eliminar ruídos. Porém, elas também podem perder detalhes da imagem. Uma forma de diminuir o problema da perda de detalhes é aplicar um realce na imagem após a filtragem. \n",
    "\n",
    "Sabe-se também que é possível aplicar realce combinando a imagem filtrada com a o resultado da sua detecção de bordas. \n",
    "\n",
    "Com base nas afirmações acima, aplique pelo menos dois filtros na imagem **figs/lena_noise.png** para diminuir o ruído. Depois, para aumentar o realce, faça uma operação aritmética de cada uma das imagens filtradas com o resultado da detecção de bordas por meio da técnica de Frei-Chen e outras duas técnicas de detecção de bordas quaisquer. Salve as imagens resultantes na pasta **figsResultado** com os nomes: \"ex07_filtro1borda1.png\", \"ex07_filtro2borda1.png\", \"ex07_filtro1borda2.png\", \"ex07_filtro2borda2.png\"  \"ex07_filtro3borda1.png\", \"ex07_filtro3borda2.png\".\n",
    "\n",
    " - trate os tons de cinza inválidos usando a técnica de saturação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Carrega a imagem\n",
    "img = cv2.imread('figs/lena_noise.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Aplica os filtros para remover ruído\n",
    "img_filtro1 = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "img_filtro2 = cv2.medianBlur(img, 3)\n",
    "\n",
    "# Aplica a detecção de bordas de Frei-Chen\n",
    "borda1 = cv2.filter2D(img, -1, np.array([[-1,-np.sqrt(2),1],[-np.sqrt(2),0,np.sqrt(2)],[1,np.sqrt(2),-1]]), borderType=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# Aplica outras duas técnicas de detecção de bordas\n",
    "borda2 = cv2.Canny(img_filtro1, 100, 200)\n",
    "borda3 = cv2.Sobel(img_filtro2, cv2.CV_8U, 1, 1)\n",
    "\n",
    "# Realça as imagens resultantes com a operação aritmética\n",
    "img_resultante1 = cv2.addWeighted(img_filtro1, 0.5, borda1, 0.5, 0)\n",
    "img_resultante2 = cv2.addWeighted(img_filtro2, 0.5, borda1, 0.5, 0)\n",
    "img_resultante3 = cv2.addWeighted(img_filtro1, 0.5, borda2, 0.5, 0)\n",
    "img_resultante4 = cv2.addWeighted(img_filtro2, 0.5, borda2, 0.5, 0)\n",
    "img_resultante5 = cv2.addWeighted(img_filtro1, 0.5, borda3, 0.5, 0)\n",
    "img_resultante6 = cv2.addWeighted(img_filtro2, 0.5, borda3, 0.5, 0)\n",
    "\n",
    "# Salva as imagens resultantes\n",
    "cv2.imwrite('figsResultado/ex07_filtro1borda1.png', img_resultante1)\n",
    "cv2.imwrite('figsResultado/ex07_filtro2borda1.png', img_resultante2)\n",
    "cv2.imwrite('figsResultado/ex07_filtro1borda2.png', img_resultante3)\n",
    "cv2.imwrite('figsResultado/ex07_filtro2borda2.png', img_resultante4)\n",
    "cv2.imwrite('figsResultado/ex07_filtro3borda1.png', img_resultante5)\n",
    "cv2.imwrite('figsResultado/ex07_filtro3borda2.png', img_resultante6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercicio 8\n",
    "\n",
    "Sabe-se que as técnicas de filtragem podem ser usadas para eliminar ruídos. Porém, elas também podem perder detalhes da imagem. Uma forma de diminuir o problema da perda de detalhes é aplicar um realce na imagem após a filtragem. \n",
    "\n",
    "Repita os códigos que você fez no exercício anterior para filtragem da imagem **figs/lena_noise.png**. Use as duas imagens resultantes como entrada de duas funções. A primeira deve fazer o realce combinando as técnicas de top-hat e bottom-hat. A segunda deve fazer o realce usando a seginte equação:\n",
    "    \n",
    "\\$$g = \n",
    "\\begin{cases}\n",
    "f \\ominus b \\text{, } & \\text{ se } f - (f \\ominus b) <  ( f \\oplus b ) - f \\\\\n",
    "f \\oplus b\\text{, } & \\text{ caso contrário }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Na equação acima,  $f \\ominus b$ é o resultado da operação de erosão no pixel $f$ usando o elemento estruturante $b$. Por outro lado, $f \\oplus b$ é o resultado da operação de dilatação no pixel $f$ usando o elemento estruturante $b$.\n",
    "\n",
    "Salve as imagens resultantes na pasta **figsResultado** com os nomes: \"ex08_filtro1morfologia1.png\", \"ex08_filtro2morfologia1.png\", \"ex08_filtro1morfologia2.png\", \"ex08_filtro2morfologia2.png\".\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregando a imagem\n",
    "img = cv2.imread('figs/lena_noise.png', 0)\n",
    "\n",
    "# Filtro de média\n",
    "img_media = cv2.blur(img, (5, 5))\n",
    "\n",
    "# Filtro Gaussiano\n",
    "img_gauss = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "def realce_top_bottom_hat(img):\n",
    "    # Definindo o elemento estruturante\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "    \n",
    "    # Aplicando a transformada top-hat\n",
    "    top_hat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "    \n",
    "    # Aplicando a transformada bottom-hat\n",
    "    bottom_hat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "    \n",
    "    # Realçando a imagem\n",
    "    img_realce = cv2.add(img, top_hat)\n",
    "    img_realce = cv2.subtract(img_realce, bottom_hat)\n",
    "    \n",
    "    return img_realce\n",
    "\n",
    "# Realce top-hat/bottom-hat para o filtro de média\n",
    "img_realce1 = realce_top_bottom_hat(img_media)\n",
    "\n",
    "# Realce top-hat/bottom-hat para o filtro gaussiano\n",
    "img_realce2 = realce_top_bottom_hat(img_gauss)\n",
    "\n",
    "def realce_eq(img):\n",
    "    # Definindo o elemento estruturante\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    \n",
    "    # Operações morfológicas\n",
    "    erode = cv2.erode(img, kernel)\n",
    "    dilate = cv2.dilate(img, kernel)\n",
    "    \n",
    "    # Calculando as diferenças\n",
    "    diff1 = cv2.absdiff(img, erode)\n",
    "    diff2 = cv2.absdiff(dilate, img)\n",
    "    \n",
    "    # Comparando as diferenças\n",
    "    img_realce = np.zeros(img.shape, np.uint8)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if diff1[i,j] < diff2[i,j]:\n",
    "                img_realce[i,j] = erode[i,j]\n",
    "            else:\n",
    "                img_realce[i,j] = dilate[i,j]\n",
    "    \n",
    "    return img_realce\n",
    "\n",
    "# Realce usando a equação para o filtro de média\n",
    "img_realce3 = realce_eq(img_media)\n",
    "\n",
    "# Realce usando a equação para o filtro gaussiano\n",
    "img_realce4 = realce_eq(img_gauss)\n",
    "\n",
    "# Salvando as imagens resultantes\n",
    "cv2.imwrite('figsResultado/ex08_filtro1morfologia1.png', img_realce1)\n",
    "cv2.imwrite('figsResultado/ex08_filtro2morfologia1.png', img_realce2)\n",
    "cv2.imwrite('figsResultado/ex08_filtro1morfologia2.png', img_realce3)\n",
    "cv2.imwrite('figsResultado/ex08_filtro2morfologia2.png', img_realce4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercicio 9\n",
    "\n",
    "Por meio das técnicas aprendidas na disciplina, tente melhorar o **máximo** possível a imagem **figs/lena_pontilhada.png**. Salve a imagem resultante na pasta **figsResultado** com o nome **ex09.png**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Carrega a imagem\n",
    "img = cv2.imread('figs/lena_pontilhada.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Cria o elemento estruturante\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "\n",
    "# Realiza a abertura na imagem (Retirar manchas brancas)\n",
    "img_opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Aplicação do filtro bilateral (Diminuição efeito quadriculado)\n",
    "img_bilateral = cv2.bilateralFilter(img_opened, 12, 150, 150)\n",
    "\n",
    "# Salva a imagem resultante\n",
    "cv2.imwrite('figsResultado/ex09.png', img_bilateral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercício 10\n",
    "\n",
    "Crie duas funções chamadas **esteg** e **decodificaEsteg**. A primeira função deve implementar uma técnica de esteganografia que consiste em camuflar uma mensagem em uma imagem. A segunda função deve decodificar a imagem gerada pela primeira.\n",
    "\n",
    "A função **esteg** deve receber uma determinada imagem de entrada e uma string. Você deverá criar uma cópia da imagem passada como entrada e deverá gravar a string nela de forma que ela fique imperceptível, mesmo com zoom na imagem.\n",
    "\n",
    "- Uma forma de atingir esse objetivo é escrever a string em uma imagem nova auxiliar. Depois usar limiarização para transformar os tons de cinza dela. Por fim, você pode usar uma operação aritmética para adicionar essa nova imagem na imagem passada como parâmetro da função.\n",
    "\n",
    "- Você pode usar a função **putText** da biblioteca OpenCV para escrever uma string em uma imagem.\n",
    "\n",
    "- Você pode considerar como premissa aumentar ou diminuir um único tom de cinza em alguns pixels de uma imagem qualquer irá gerar uma alteração visualmente imperceptível. \n",
    "\n",
    "\n",
    "A função **decodificaEsteg** deve receber duas imagem. A primeira delas é uma imagem que contém uma mensagem escondida. A segunda imagem é a original antes da operação de esteganografia. A função deve retornar uma nova imagem que torne visível a mensagem camuflada possibilitante a leitura dela.\n",
    "\n",
    " - Uma operação aritmética pode ser usada para extrair a imagem escondida\n",
    " - A limiarização pode ser usada para transformar os tons de cinza da mensagem escondida em um tom de cinza desejado para facilitar a visualização.\n",
    " \n",
    "Use a função **esteg** para esconder a string dentro da imagem **facens2.jpg**, mostre a imagem resultante na tela e salve na pasta **figsResultado** com o nome **ex10_esteganografia.png**\n",
    "\n",
    "Use a função **decodificaEsteg** para revelar a mensagem contida dentro da imagem retornada pela primeira função. Mostre a imagem resultante na tela e salve na pasta **figsResultado** com o nome **ex10_mesgDecodificada.png**.\n",
    "\n",
    "Obs: as funções acima devem ser genéricas, ou seja, devem funcionar para quaisquer imagens passadas como entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/gabrieldias/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def esteg(imagem, mensagem):\n",
    "    # Cria uma cópia da imagem de entrada\n",
    "    novaImagem = imagem.copy()\n",
    "    \n",
    "    # Cria uma imagem auxiliar para armazenar a mensagem\n",
    "    msgImagem = np.zeros(imagem.shape[:2], dtype=np.uint8)\n",
    "    cv2.putText(msgImagem, mensagem, (0, msgImagem.shape[0]//2), cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2)\n",
    "\n",
    "    # Aplica uma limiarização na imagem auxiliar para transformar os tons de cinza em 0 e 255\n",
    "    _, msgImagem = cv2.threshold(msgImagem, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Aplica uma operação aritmética para adicionar a imagem auxiliar na imagem de entrada\n",
    "    novaImagem[:,:,0] = cv2.add(novaImagem[:,:,0], msgImagem)\n",
    "    \n",
    "    return novaImagem\n",
    "\n",
    "def decodificaEsteg(imagemCamuflada, imagemOriginal):\n",
    "    # Extrai a imagem camuflada através de uma operação aritmética\n",
    "    imgExtraida = cv2.absdiff(imagemCamuflada, imagemOriginal)\n",
    "    \n",
    "    # Aplica uma limiarização para transformar os tons de cinza em 0 e 255\n",
    "    _, imgExtraida = cv2.threshold(imgExtraida[:,:,0], 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return imgExtraida\n",
    "\n",
    "# Lê a imagem de entrada\n",
    "imagem = cv2.imread('figs/facens2.jpg')\n",
    "\n",
    "# Esconde a mensagem na imagem\n",
    "mensagem = 'Esta é uma mensagem secreta!'\n",
    "imagemCamuflada = esteg(imagem, mensagem)\n",
    "\n",
    "# Mostra a imagem resultante na tela e salva na pasta figsResultado\n",
    "cv2.imshow('Imagem camuflada', imagemCamuflada)\n",
    "cv2.imwrite('figsResultado/ex10_esteganografia.png', imagemCamuflada)\n",
    "\n",
    "# Decodifica a mensagem da imagem camuflada\n",
    "imgExtraida = decodificaEsteg(imagemCamuflada, imagem)\n",
    "\n",
    "# Mostra a mensagem decodificada na tela e salva na pasta figsResultado\n",
    "cv2.imshow('Mensagem decodificada', imgExtraida)\n",
    "cv2.imwrite('figsResultado/ex10_mesgDecodificada.png', imgExtraida)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "brincando_imagens.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
